---
title: 'Lending Club Interest Rate Study in R.'
date: '8/3/2021'
output:
  html_document: 
    theme: readable
    toc: yes  
    code_folding: show
  pdf_document: default
css: report.css
urlcolor: cyan
editor_options: 
  chunk_output_type: console
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80, fig.align = "center",
        fig.height = 5, fig.width = 7)
```

*Utility functions defined here, click `Code` to see*

```{r message=FALSE, warning=FALSE, class.source = 'fold-hide'}
library(knitr)
library(kableExtra)
library(dplyr)
library(MASS)

format_numerics <- function(data, digits = 2, notation_threshold = 0.00001) {
  # make sure is a data.frame, then format
  if(!is.data.frame(data)){
    data <- as.data.frame(data)
  }  
  data %>% 
    mutate_if(
      is.numeric, 
      function(x) {
        if_else(
          abs(x) < notation_threshold, 
          formatC(x, digits = digits, format = "e"), 
          formatC(x, digits = digits, format = "f", drop0trailing = FALSE)
        )
      }
    )
}

gen_kable <- function(table_data, add_row_names = TRUE, caption = "", foot_text = "", col_names = c(), row_names = c()) {
  f_data <- format_numerics(table_data) 
  if(length(col_names) != 0){
    colnames(f_data) <- col_names
  }
  if(length(row_names) != 0){
    rownames(f_data) <- row_names
  }  
  f_data %>%
  kable(., format = "html", row.names = add_row_names,
        caption = caption, 
        escape = FALSE) %>%
    kable_styling(bootstrap_options = c("striped", "hover"),
                  full_width = F,
                  font_size = 14,
                  position = "center") %>%
    footnote(general = foot_text)
}

```

# Introduction

## About the Data

The dataset contains background data on loans made through the LendingClub platform, an online peer-to-peer lender in which investors were able provide personal loans to borrowers. The platform shut down in 2020. The data was publicly available through the LendingClub website prior to its shutdown, but is included in the `openintro` package in R.

*From the R documentation:*

> This data set represents thousands of loans made through the Lending Club platform, which is a platform that allows individuals to lend to other individuals. Of course, not all loans are created equal. Someone who is a essentially a sure bet to pay back a loan will have an easier time getting a loan with a low interest rate than someone who appears to be riskier. And for people who are very risky? They may not even get a loan offer, or they may not have accepted the loan offer due to a high interest rate. It is important to keep that last part in mind, since this data set only represents loans actually made, i.e. do not mistake this data for loan applications!

The dataset can be accessed by installing the `R package` below.

```{r, eval=FALSE}
install.packages("openintro")
```

```{r, message=FALSE}
library("openintro")
```

Number of variables: **`r dim(loans_full_schema)[2]`**

Number of observations: **`r dim(loans_full_schema)[1]`**

## Statement of interest

We are interested in this dataset because it is a good example of the kind of data that will be analyzed in the private sector. Many industries consider income and credit history in making business decisions. Not only will this provide a quality learning opportunity involving real-world data, but will also provide a tangible example of statistical modeling experience that we can use as we continue our data science careers.

## Goal of the Model

This study aims to to find a `model` that can predict the  `interest_rate` given the available variables excluding `grade` and `subgrade`. 

By fitting a simple model using the `grade` we can see a high $R^2$.

```{r}
model_with_grade = lm(interest_rate ~ grade, data = loans_full_schema)

r2_w_grade = summary(model_with_grade)$r.squared
```

Given the high $R^2$ value of `r r2_w_grade`. Seems like it explains our `response` variable very well.

Our goal in this study is to look for a model using a set of the other predictors that can also explain the `interest_rate`.

# Methods

## Utility functions.

Here we define `functions` that will be of use during the study.

The following `function` will help us to report diagnostics such as:

- Normality.
- Constant Variance.

```{r, message = FALSE, warning = FALSE}
library(lmtest)

diagnostics <- function(model, alpha = 0.05) {

  diags <- list()
  p_val_st <- shapiro.test(model$residuals)$p.value
  p_val_bp <- bptest(model)$p.value
  diags$shapiro <- list(
    "p_val" = p_val_st,
    "decision" = ifelse(p_val_st < alpha, "Reject", "Fail to Reject"))
  diags$bptest <- list(
    "p_val" = p_val_bp,
    "decision" = ifelse(p_val_bp < alpha, "Reject", "Fail to Reject"))
  
  diags
}
```

The function below will show the `QQ` and `Fitted vs Residuals` plots for a given model.

```{r}
diagnostic_graph <- function(model, pcol = "grey", lcol = "dodgerblue") {
  par(mfrow = c(1, 2), bg="ghostwhite")
  plot(model$fitted.values, model$residuals,  
       col = pcol, pch = 20,
       xlab = "Fitted", ylab = "Residuals",
       main = "Fitted vs Residuals")
  abline(h = 0, col = lcol, lwd = 2)
  qqnorm(model$residuals, main = "Normal Q-Q Plot", 
         col = pcol)
  qqline(model$residuals, col = lcol, lwd = 2)
}
```


## Variables Selection and Data Preparation

- For simplicity we start removing a few columns that have many `NA` values.
- Remove some not relevant variables like dates and descriptions.
- For this study we also remove `grade` and `sub_grade`.

```{r}
## Remove columns with many NAs
loans_data <- subset(loans_full_schema, 
                     select = -c(num_accounts_120d_past_due,
                                 months_since_last_credit_inquiry,
                                 months_since_90d_late,
                                 months_since_last_delinq,
                                 debt_to_income_joint,
                                 verification_income_joint,
                                 annual_income_joint,
                                 emp_length
                     ))

## Remove unimportant
loans_data <- subset(loans_data, 
                     select = -c(
                       state,
                       emp_title,
                       issue_month
                     ))

## Remove 24 entrie with NA dept_to_income
loans_data <- na.omit(loans_data)

## Remove some categoricals
loans_data <- subset(loans_data, 
                     select = -c(
                       loan_status,
                       initial_listing_status,
                       disbursement_method,
                       grade,
                       sub_grade
                     ))

## Conceptually we should remove the following field,
## as they are a result of the interest rate.
loans_data <- subset(loans_data, 
                     select = -c(
                      paid_total,
                      paid_principal,
                      paid_interest,
                      paid_late_fees,
                      installment,
                      balance
                     ))
```

Convert some variables to `factors`.

```{r}
loans_data$homeownership <- as.factor(loans_data$homeownership)
loans_data$verified_income <- as.factor(loans_data$verified_income)
loans_data$application_type <- as.factor(loans_data$application_type)
loans_data$term <- as.factor(loans_data$term)
```

Divide Training and Testing Data.

```{r}
# Remove before submitting !!
set.seed(420)

idxs <- 1:nrow(loans_data)
trn_idxs <- sample(idxs, 1200) # CHANGE before submitting

##### Remove before submitting
sample_idxs <- sample(idxs, 1500)
loans_data <- loans_data[sample_idxs, ]
#####

# Train and Test sets
loans_train <- loans_data[trn_idxs, ]
loans_test <- loans_data[-trn_idxs, ]
```

## Collinearity Analysis (Bryan)

## Unusual Observations (Bryan)

- leverage
- outliers
- influence

## Transformations (Alejandro)

A first check into the `Linear Model Assuptions` suggests we might need to try some transformations.

```{r, fig.height = 5, fig.width = 7, fig.align = "center"}
additive_mod <- lm(interest_rate ~ ., data = loans_train)

diagnostic_graph(additive_mod)
```

### Response Transformation

Since our response variable `interest_rate` is a positive `numeric` value, we explore a `Box-Cox Transformation` as defined below.

$$
g_\lambda(y) = \left\{
\begin{array}{lr}\displaystyle\frac{y^\lambda - 1}{\lambda} &  \lambda \neq 0\\
        & \\
       \log(y) &  \lambda = 0
     \end{array}
   \right.
$$

```{r, fig.height = 5, fig.width = 7, fig.align = "center"}
par(mfrow=c(1, 1), bg="ghostwhite")
boxcox(additive_mod, plotit = TRUE, lambda = seq(-0.8, 0.8, by = 0.1))
```

Since $\lambda \approx 0$, we try to apply a $log$ `transformation` of the `response`.

```{r, fig.height = 5, fig.width = 7, fig.align = "center"}
additive_mod <- lm(log(interest_rate) ~ ., data = loans_train)

diagnostic_graph(additive_mod)
```

We noticed a significant improvement in the `QQ Plot`, yet we still see an obvious pattern in the `Fitted vs Residuals` plot.

### Predictors Transformation

Below plots show the relation between 4 the predictors and the response.

```{r, fig.height = 5, fig.width = 7, fig.align = "center"}
par(mfrow=c(2, 2), bg="ghostwhite")

plot(interest_rate ~ accounts_opened_24m, 
     xlab = "Predictor (accounts_opened_24m)",
     ylab = "Response (interest_rate)",
     data = loans_data, col = "deepskyblue3", pch = 20,
     main = "Accounts Opened vs Interest Rate")

plot(interest_rate ~ total_debit_limit, 
     xlab = "Predictor (total_debit_limit)",
     ylab = "Response (interest_rate)",
     data = loans_data, col = "deepskyblue3", pch = 20,
     main = "Total Debit Limit vs Interest Rate")

plot(interest_rate ~ installment, 
     xlab = "Predictor (installment)",
     ylab = "Response (interest_rate)",
     data = loans_data, col = "deepskyblue3", pch = 20,
     main = "Installment (monthly payment) vs Interest Rate")

plot(interest_rate ~ total_credit_limit, 
     xlab = "Predictor (total_credit_limit)",
     ylab = "Response (interest_rate)",
     data = loans_data, col = "deepskyblue3", pch = 20,
     main = "Total Credit Limit vs Interest Rate")

```

From the plots above, there is no obvious correlation from which we can decide a transformation to apply. In fact, we tried a few of them without noticing much improvement in the `QQ plot` and `Fitted vs Residuals`.

## Model Selection (Joshua)

```{r}
additive = lm(interest_rate ~ . - num_satisfactory_accounts - num_accounts_30d_past_due - installment - balance
- num_open_cc_accounts - num_cc_carrying_balance - num_historical_failed_to_pay - paid_total
- paid_principal - paid_interest - paid_late_fees - loan_purpose - num_total_cc_accounts, data = loans_train)

n = length(resid(additive))
selected_aic = step(additive, direction = "backward", trace = FALSE)
selected_bic = step(additive, direction = "backward", k = log(n), trace = FALSE)
```


```{r}
log_additive = lm(log(interest_rate) ~ .- num_satisfactory_accounts - num_accounts_30d_past_due - installment - balance
- num_open_cc_accounts - num_cc_carrying_balance - num_historical_failed_to_pay - paid_total
- paid_principal - paid_interest - paid_late_fees - loan_purpose - num_total_cc_accounts, data = loans_train)

n = length(resid(log_additive))
log_selected_aic = step(log_additive, direction = "backward", trace = FALSE)
log_selected_bic = step(log_additive, direction = "backward", k = log(n), trace = FALSE)
```

##Generate interactive model from best selected
```{r}
interactive = lm(interest_rate ~ (verified_income + debt_to_income + 
    delinq_2y + inquiries_last_12m + total_credit_lines + total_credit_limit + 
    total_credit_utilized + accounts_opened_24m + num_active_debit_accounts + 
    total_debit_limit + num_mort_accounts + account_never_delinq_percent + 
    term) ^ 2, data = loans_train)

log_interactive = lm(log(interest_rate) ~ (verified_income + debt_to_income + 
    delinq_2y + inquiries_last_12m + total_credit_lines + total_credit_limit + 
    total_credit_utilized + accounts_opened_24m + num_active_debit_accounts + 
    total_debit_limit + num_mort_accounts + account_never_delinq_percent + 
    public_record_bankrupt + term) ^ 2, data = loans_train)
```


## Final Model Diagnostics (Alejandro)




Normality
Constant Variance
Linearity

# Results

## Model Metrics
```{r}
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

adjrsquared = c(summary(additive)$adj.r.squared, summary(selected_aic)$adj.r.squared, summary(selected_bic)$adj.r.squared,
                summary(interactive)$adj.r.squared, summary(log_additive)$adj.r.squared, summary(log_selected_aic)$adj.r.squared,
                summary(log_selected_bic)$adj.r.squared, summary(log_interactive)$adj.r.squared)
loocv_rmse = c(calc_loocv_rmse(additive), calc_loocv_rmse(selected_aic), calc_loocv_rmse(selected_bic), calc_loocv_rmse(interactive),
               calc_loocv_rmse(log_additive), calc_loocv_rmse(log_selected_aic), calc_loocv_rmse(log_selected_bic), calc_loocv_rmse(log_interactive))

model_metrics <- data.frame (Model=c("Additive", "Backwards AIC", "Backwards BIC", "Interactive", "Additive(log)", "Backwards AIC(log)", "Backwards BIC(log)", "Interactive(log)"),
                  "Adjusted R^2" = adjrsquared,
                  "LOOCV-RMSE" = loocv_rmse,
                  check.names=FALSE)

gen_kable(model_metrics,
          caption = "Model Metrics")
```



# Discussion

